{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renanpyd/Course_Google_Colab/blob/main/site/en/tutorials/distribute/save_and_load.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "CPSnXS88KFEo"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xNCIO5hiCj"
      },
      "source": [
        "# Save and load a model using a distribution strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0lG6qgThxAS"
      },
      "source": [
        "## Overview\n",
        "\n",
        "It's common to save and load a model during training. There are two sets of APIs for saving and loading a keras model: a high-level API, and a low-level API. This tutorial demonstrates how you can use the SavedModel APIs when using `tf.distribute.Strategy`. To learn about SavedModel and serialization in general, please read the [saved model guide](../../guide/saved_model.ipynb), and the [Keras model serialization guide](https://www.tensorflow.org/guide/keras/save_and_serialize). Let's start with a simple example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FITHltVKQ4eZ"
      },
      "source": [
        "Import dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RWG5HchAiOrZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqapWj98ptNV"
      },
      "source": [
        "Prepare the data and model using `tf.distribute.Strategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yrYiAf_ziRyw",
        "outputId": "9959842d-f97e-4ce9-81ce-dc19822125ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        }
      ],
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "def get_data():\n",
        "  datasets, ds_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "  mnist_train, mnist_test = datasets['train'], datasets['test']\n",
        "\n",
        "  BUFFER_SIZE = 10000\n",
        "\n",
        "  BATCH_SIZE_PER_REPLICA = 64\n",
        "  BATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync\n",
        "\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "  eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n",
        "\n",
        "  return train_dataset, eval_dataset\n",
        "\n",
        "def get_model():\n",
        "  with mirrored_strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmU4Y3feS9Na"
      },
      "source": [
        "Train the model: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zmGurbJmS_vN",
        "outputId": "1d35f3b5-2bdf-4eaf-d108-f14a9da81b38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294,
          "referenced_widgets": [
            "e0a90452a8e24df199b907e79ab10298",
            "106fa58d00414cd09d10ad07d866af12",
            "8ee9250ee6a649fda90b4bad8c89509f",
            "f4b127e5934d40bd9558055c5b637a2a",
            "bc32eb7db52446a59cfe7422feaa8941",
            "0c3f42cfa055482b96f44cd2fd113de3",
            "cb61ef0c761047a79ebe85f0e37a7d11",
            "e1449a037e38490ba9d515fd866f1186",
            "cd6bc1115360430f8a9f0fa300479792",
            "4685c81ab44640ba940d24d050fbe4f0",
            "f59d89265d8e4569af91e3fba5539312"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0a90452a8e24df199b907e79ab10298",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
            "Epoch 1/2\n",
            "938/938 [==============================] - 47s 46ms/step - loss: 0.2021 - sparse_categorical_accuracy: 0.9410\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 27s 28ms/step - loss: 0.0661 - sparse_categorical_accuracy: 0.9803\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f596a171d50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model = get_model()\n",
        "train_dataset, eval_dataset = get_data()\n",
        "model.fit(train_dataset, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L01wjgvRizHS"
      },
      "source": [
        "## Save and load the model\n",
        "\n",
        "Now that you have a simple model to work with, let's take a look at the saving/loading APIs. \n",
        "There are two sets of APIs available:\n",
        "\n",
        "*   High level keras `model.save` and `tf.keras.models.load_model`\n",
        "*   Low level `tf.saved_model.save` and `tf.saved_model.load`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX_IF2F1tvFs"
      },
      "source": [
        "### The Keras APIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8xfceg4Z3H_"
      },
      "source": [
        "Here is an example of saving and loading a model with the Keras APIs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LYOStjV5knTQ",
        "outputId": "de192159-f6de-4b2d-aa10-2439478201bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ]
        }
      ],
      "source": [
        "keras_model_path = \"/tmp/keras_save\"\n",
        "model.save(keras_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvQIdQp3zNMp"
      },
      "source": [
        "Restore the model without `tf.distribute.Strategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WrXAAVtrzRgv",
        "outputId": "880340e6-5988-4ea6-ac84-ae156c20a6d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 27s 28ms/step - loss: 0.0462 - sparse_categorical_accuracy: 0.9862\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9902\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f596802cd10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "restored_keras_model = tf.keras.models.load_model(keras_model_path)\n",
        "restored_keras_model.fit(train_dataset, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYAnskzorda-"
      },
      "source": [
        "After restoring the model, you can continue training on it, even without needing to call `compile()` again, since it is already compiled before saving. The model is saved in the TensorFlow's standard `SavedModel` proto format. For more information, please refer to [the guide to `saved_model` format](../../guide/saved_model.ipynb).\n",
        "\n",
        "Now to load the model and train it using a `tf.distribute.Strategy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wROPrJaAqBQz",
        "outputId": "cde82c0f-8da9-485c-a89c-45f0ea8c9257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 27s 28ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9860\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9903\n"
          ]
        }
      ],
      "source": [
        "another_strategy = tf.distribute.OneDeviceStrategy(\"/cpu:0\")\n",
        "with another_strategy.scope():\n",
        "  restored_keras_model_ds = tf.keras.models.load_model(keras_model_path)\n",
        "  restored_keras_model_ds.fit(train_dataset, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdiiPmL5tQk5"
      },
      "source": [
        "As you can see, loading works as expected with `tf.distribute.Strategy`. The strategy used here does not have to be the same strategy used before saving. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CrXIbmFt0f6"
      },
      "source": [
        "### The `tf.saved_model` APIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtGzPp6et4Em"
      },
      "source": [
        "Now let's take a look at the lower level APIs. Saving the model is similar to the keras API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4y6T31APuCqK",
        "outputId": "2d39d0b9-ae25-4481-86df-3304ded369a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ]
        }
      ],
      "source": [
        "model = get_model()  # get a fresh model\n",
        "saved_model_path = \"/tmp/tf_save\"\n",
        "tf.saved_model.save(model, saved_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1QNRYcwuRll"
      },
      "source": [
        "Loading can be done with `tf.saved_model.load()`. However, since it is an API that is on the lower level (and hence has a wider range of use cases), it does not return a Keras model. Instead, it returns an object that contain functions that can be used to do inference. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aaEKqBSPwAuM"
      },
      "outputs": [],
      "source": [
        "DEFAULT_FUNCTION_KEY = \"serving_default\"\n",
        "loaded = tf.saved_model.load(saved_model_path)\n",
        "inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x65l7AaHUZCA"
      },
      "source": [
        "The loaded object may contain multiple functions, each associated with a key. The `\"serving_default\"` is the default key for the inference function with a saved Keras model. To do an inference with this function: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5Ore5q8-UjW1",
        "outputId": "f6d33a2b-9e6c-46bb-a4df-4678d09facca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dense_3': <tf.Tensor: shape=(64, 10), dtype=float32, numpy=\n",
            "array([[ 1.16263792e-01, -1.48768961e-01, -5.68470061e-02,\n",
            "         8.89102295e-02,  1.47642255e-01,  2.45972211e-03,\n",
            "         1.70727327e-01, -4.32521701e-02, -4.76435982e-02,\n",
            "        -1.86492741e-01],\n",
            "       [ 8.87650624e-02, -1.29915401e-01, -1.44106701e-01,\n",
            "         8.45202580e-02,  1.58131957e-01, -1.25832513e-01,\n",
            "         2.34356016e-01,  2.37279106e-02,  6.01329356e-02,\n",
            "         1.60128437e-02],\n",
            "       [-3.34433950e-02, -1.41287431e-01,  1.09615065e-01,\n",
            "         9.27858278e-02, -3.03213317e-02,  1.45251350e-02,\n",
            "         4.03764248e-02,  8.51287097e-02, -1.24564409e-01,\n",
            "        -1.39216073e-02],\n",
            "       [ 1.88611597e-02, -6.81044832e-02, -5.59889302e-02,\n",
            "         1.18776582e-01, -2.52634287e-02, -8.34486127e-05,\n",
            "         5.10085970e-02,  1.60209417e-01, -7.50030279e-02,\n",
            "        -6.95607215e-02],\n",
            "       [-6.70917984e-03,  3.70143205e-02, -1.25214001e-02,\n",
            "         2.76501834e-01, -5.54026961e-02,  5.19630760e-02,\n",
            "         1.52248025e-01,  8.29505846e-02,  3.39038000e-02,\n",
            "         4.34645414e-02],\n",
            "       [-5.78504950e-02, -2.07599327e-01,  1.37864640e-02,\n",
            "         1.44507915e-01,  9.58923697e-02, -4.78528179e-02,\n",
            "         1.96200952e-01, -3.10831126e-02, -3.10721342e-02,\n",
            "        -1.11428685e-01],\n",
            "       [ 3.76081727e-02, -2.00374082e-01, -1.22259529e-02,\n",
            "         2.02356383e-01, -6.57602102e-02, -9.21087489e-02,\n",
            "         1.21804453e-01,  9.55816954e-02, -3.20251025e-02,\n",
            "         1.00484200e-01],\n",
            "       [-2.80261948e-03, -1.67704523e-01, -2.00327765e-02,\n",
            "         1.14775665e-01,  3.01650930e-02, -1.05740204e-02,\n",
            "         5.39789312e-02,  1.77337807e-02, -1.20109022e-02,\n",
            "        -1.60801895e-02],\n",
            "       [ 1.13832936e-01, -2.40152195e-01, -9.47004333e-02,\n",
            "         1.66458219e-01,  1.07881121e-01, -2.62227356e-02,\n",
            "         1.70902580e-01,  6.47296431e-03,  3.06705441e-02,\n",
            "        -7.23612607e-02],\n",
            "       [-7.55211785e-02, -6.36335388e-02,  2.73518008e-03,\n",
            "         2.64831372e-02,  6.76584840e-02, -1.18932230e-02,\n",
            "         1.41700298e-01,  3.85316089e-03,  1.38773685e-02,\n",
            "         6.10252544e-02],\n",
            "       [ 5.44108590e-03, -2.04392418e-01, -6.72154594e-04,\n",
            "         2.15490267e-01,  6.49558529e-02, -1.66050509e-01,\n",
            "         2.74399277e-02,  1.82190090e-01, -6.42316267e-02,\n",
            "        -3.46678123e-02],\n",
            "       [ 4.57836868e-04, -2.35193834e-01, -8.86140168e-02,\n",
            "         1.67670041e-01,  3.37596498e-02, -5.96633740e-03,\n",
            "         1.49629265e-01, -6.10881299e-02, -1.01041896e-02,\n",
            "        -1.09481409e-01],\n",
            "       [-7.24516660e-02, -5.13634831e-02,  8.60833004e-02,\n",
            "         2.41607040e-01, -1.39340749e-02, -7.95154795e-02,\n",
            "         1.83903754e-01,  2.02908918e-01, -2.43380312e-02,\n",
            "         1.70135483e-01],\n",
            "       [-3.59186381e-02, -1.21293202e-01,  3.13305743e-02,\n",
            "         1.84372813e-01, -1.48973111e-02, -4.04753685e-02,\n",
            "         1.37910694e-01,  1.55078858e-01, -1.52675018e-01,\n",
            "         3.39486562e-02],\n",
            "       [ 1.05137220e-02, -9.06091034e-02, -4.91023064e-02,\n",
            "         1.45613641e-01,  5.23637459e-02,  1.82832200e-02,\n",
            "         1.56746209e-01,  1.16770782e-01, -8.01752061e-02,\n",
            "        -5.45426644e-02],\n",
            "       [-9.10192803e-02, -7.29695428e-04,  7.74228349e-02,\n",
            "         1.08099453e-01, -5.38550317e-02, -1.85389239e-02,\n",
            "         8.66518095e-02,  2.03577638e-01, -9.22842398e-02,\n",
            "        -9.79225039e-02],\n",
            "       [ 1.00357413e-01, -1.94525287e-01, -4.31648865e-02,\n",
            "         2.04657137e-01, -8.30284879e-03, -4.40253094e-02,\n",
            "         1.62795279e-02,  9.13213715e-02, -4.11673076e-02,\n",
            "        -9.05330200e-03],\n",
            "       [-4.80871042e-03, -1.24622583e-01, -6.83367103e-02,\n",
            "         1.23448238e-01,  3.01504321e-02, -1.09344363e-01,\n",
            "         1.02073677e-01,  1.94490418e-01, -1.59829929e-02,\n",
            "         3.77838500e-02],\n",
            "       [ 3.50974570e-03, -2.18685716e-01,  8.34388733e-02,\n",
            "         2.19818398e-01,  2.54797097e-02, -1.25312075e-01,\n",
            "         8.62592235e-02,  1.27196684e-01, -1.72792912e-01,\n",
            "         1.16165653e-02],\n",
            "       [ 2.65232045e-02,  1.40469894e-02, -1.07244529e-01,\n",
            "         1.98441058e-01,  7.18243942e-02,  6.55198172e-02,\n",
            "         1.43342748e-01,  1.34038016e-01, -1.84561107e-02,\n",
            "        -8.27816948e-02],\n",
            "       [-6.20517954e-02, -1.85468137e-01,  7.96831846e-02,\n",
            "         1.29337415e-01, -9.82421637e-03, -3.86731699e-03,\n",
            "         9.84588712e-02,  7.90402144e-02, -5.26910014e-02,\n",
            "        -9.68754888e-02],\n",
            "       [-4.21420820e-02, -3.70436423e-02,  2.47990005e-02,\n",
            "         1.59978755e-02,  2.16107704e-02,  4.16750535e-02,\n",
            "         1.49903530e-02,  1.52294323e-01, -3.04403733e-02,\n",
            "         2.12564021e-02],\n",
            "       [-5.95394522e-02, -2.02168077e-01,  5.61990850e-02,\n",
            "         1.29334092e-01, -5.11924736e-02, -5.01352772e-02,\n",
            "         1.45535484e-01,  1.03907295e-01,  2.85547040e-02,\n",
            "        -2.81132758e-02],\n",
            "       [-4.76083085e-02,  9.21421219e-03,  5.18637942e-03,\n",
            "         1.66804567e-01,  1.25482500e-01, -6.02123253e-02,\n",
            "         2.27794960e-01, -1.64152905e-02,  1.01937875e-01,\n",
            "         3.11934529e-03],\n",
            "       [-3.64149152e-03, -1.46500254e-02, -8.46935436e-02,\n",
            "         1.30713331e-02,  1.24836706e-01, -2.10662652e-02,\n",
            "         1.39233068e-01,  7.85610229e-02,  1.88550185e-02,\n",
            "         3.68548632e-02],\n",
            "       [ 8.60390514e-02, -2.95268685e-01, -5.37152849e-02,\n",
            "         1.67290121e-01, -8.38358849e-02, -5.46692125e-02,\n",
            "         6.09432161e-02,  1.24921642e-01, -7.82064274e-02,\n",
            "        -1.05278566e-02],\n",
            "       [ 7.64886364e-02, -1.17411815e-01, -5.75547144e-02,\n",
            "         1.32868648e-01,  4.14189212e-02, -1.73361674e-02,\n",
            "         1.08877473e-01,  1.31687418e-01, -5.47338612e-02,\n",
            "         1.76483486e-02],\n",
            "       [ 4.92789075e-02, -2.61685431e-01, -3.79738882e-02,\n",
            "         1.30310133e-01,  7.47572184e-02, -1.10687669e-02,\n",
            "         2.11188957e-01,  4.61005466e-03,  2.68308911e-02,\n",
            "        -1.18893526e-01],\n",
            "       [-8.14159662e-02,  5.18213511e-02,  1.55603103e-02,\n",
            "         1.33937731e-01, -7.79626742e-02, -1.67465601e-02,\n",
            "         1.77980810e-01,  1.04057506e-01, -2.41691303e-02,\n",
            "        -2.67651547e-02],\n",
            "       [-4.17576954e-02, -6.05562925e-02, -2.37191226e-02,\n",
            "         1.16175041e-01,  5.52982092e-02, -5.03059924e-02,\n",
            "         5.81616051e-02,  7.74480850e-02, -3.86582203e-02,\n",
            "        -6.68514967e-02],\n",
            "       [ 1.58947688e-02, -2.15772893e-02, -6.64553419e-02,\n",
            "         1.39631137e-01, -4.22192365e-02, -9.41904821e-03,\n",
            "         2.55839210e-02,  1.63930431e-01, -1.30328670e-01,\n",
            "         1.28398975e-02],\n",
            "       [ 7.53245503e-02, -2.58250058e-01, -3.39359487e-03,\n",
            "         2.00158179e-01, -3.07922475e-02, -9.80338305e-02,\n",
            "         5.75239174e-02,  1.43430218e-01, -3.03254630e-02,\n",
            "         4.64884453e-02],\n",
            "       [ 2.28753891e-02, -2.59735346e-01,  4.76471595e-02,\n",
            "         2.29621649e-01,  3.91113684e-02, -1.12856477e-01,\n",
            "         1.41454995e-01,  3.78989652e-02, -9.43393037e-02,\n",
            "        -5.72708212e-02],\n",
            "       [-6.75537065e-02, -6.21787906e-02,  2.76894681e-02,\n",
            "         7.58636892e-02, -8.18835869e-02, -5.12148403e-02,\n",
            "         1.08909301e-01,  4.99991551e-02, -4.36729677e-02,\n",
            "         1.88825876e-02],\n",
            "       [ 9.99127701e-02, -1.89499348e-01, -6.56646341e-02,\n",
            "         1.52828276e-01,  5.37374765e-02, -6.69717938e-02,\n",
            "         1.35665476e-01, -2.07914095e-02, -7.19210953e-02,\n",
            "        -7.86738321e-02],\n",
            "       [-4.98734787e-02, -2.94628330e-02,  9.65806469e-02,\n",
            "         6.58228025e-02, -1.27558932e-01, -4.32277098e-02,\n",
            "         1.45112332e-02,  2.24444449e-01, -1.88764930e-01,\n",
            "        -5.95373809e-02],\n",
            "       [ 7.18244463e-02, -2.36022100e-01, -9.91808325e-02,\n",
            "         1.32572606e-01,  1.88695062e-02,  2.64042802e-02,\n",
            "         1.57438174e-01, -1.03260214e-02, -1.00683182e-01,\n",
            "        -1.46374002e-01],\n",
            "       [-1.02730263e-02, -1.24998197e-01,  4.14379500e-03,\n",
            "         2.03010350e-01,  2.15673838e-02, -5.33587076e-02,\n",
            "         6.63190931e-02,  1.33399069e-01, -6.47016466e-02,\n",
            "        -1.89072583e-02],\n",
            "       [ 2.03338526e-02, -1.18668444e-01, -9.75033455e-03,\n",
            "         7.36687034e-02, -1.65655129e-02,  6.12605102e-02,\n",
            "         7.24998936e-02,  3.09333019e-02, -6.73595443e-02,\n",
            "        -1.06173474e-02],\n",
            "       [-2.83480622e-03, -9.11279693e-02,  3.35776918e-02,\n",
            "         6.94940239e-02, -4.05067243e-02, -9.28520635e-02,\n",
            "        -2.24483572e-02,  2.93276519e-01, -1.55120715e-01,\n",
            "        -1.40747381e-02],\n",
            "       [-4.08512913e-02, -1.47265017e-01,  1.06109001e-01,\n",
            "         1.76931977e-01, -8.95541441e-03, -4.61014640e-03,\n",
            "         1.82314768e-01,  3.18247341e-02,  1.19164325e-02,\n",
            "        -6.09145090e-02],\n",
            "       [-5.26695652e-03, -4.86856475e-02,  3.54363397e-02,\n",
            "         1.66339114e-01,  5.52638108e-03, -9.52857137e-02,\n",
            "         1.03064649e-01,  1.18033782e-01, -4.54226173e-02,\n",
            "         7.89657310e-02],\n",
            "       [-3.41772847e-02, -1.85090661e-01,  5.83728664e-02,\n",
            "         1.44317389e-01, -1.04270433e-03, -1.42123446e-01,\n",
            "         7.06534600e-03,  8.71214867e-02, -6.50032163e-02,\n",
            "         1.98437646e-02],\n",
            "       [ 5.64970709e-02, -3.87235619e-02, -1.06165400e-02,\n",
            "         1.30135939e-01,  8.68031308e-02,  5.01698814e-03,\n",
            "         5.16407341e-02,  7.68892094e-02,  5.86954169e-02,\n",
            "         3.69667970e-02],\n",
            "       [-9.37778428e-02, -1.75720993e-02,  9.00703520e-02,\n",
            "         1.20274208e-01, -6.96418732e-02,  7.14097396e-02,\n",
            "         7.82805532e-02,  1.41814619e-01, -1.21372990e-01,\n",
            "        -1.20863631e-01],\n",
            "       [ 8.99271294e-02, -1.49602726e-01, -5.15161790e-02,\n",
            "         1.29563510e-01,  2.46616174e-02,  7.51333311e-02,\n",
            "         7.25291446e-02,  9.34706926e-02,  8.06135461e-02,\n",
            "         1.45809846e-02],\n",
            "       [-2.69499607e-02, -2.86147781e-02,  1.31127492e-01,\n",
            "         1.56357527e-01, -2.52551474e-02,  1.94710381e-02,\n",
            "         1.23014562e-01,  1.31097361e-01, -7.00503662e-02,\n",
            "         1.23220980e-01],\n",
            "       [ 2.39379890e-02, -1.69573531e-01, -1.27122402e-01,\n",
            "         2.13462040e-01, -4.74591460e-03, -1.07328147e-01,\n",
            "         1.74877539e-01,  6.26541525e-02, -6.03728592e-02,\n",
            "        -1.04437536e-02],\n",
            "       [-4.84208092e-02, -7.33821318e-02,  2.36584898e-03,\n",
            "         1.97640121e-01, -1.48003809e-02, -3.10211442e-02,\n",
            "         1.43146351e-01,  1.00624837e-01, -1.85078830e-01,\n",
            "         2.92383395e-02],\n",
            "       [-9.05630644e-03, -1.32249415e-01,  2.94152349e-02,\n",
            "         5.15568145e-02,  3.10217850e-02,  3.06776483e-02,\n",
            "         5.93007617e-02,  3.75852324e-02,  1.89348664e-02,\n",
            "        -3.06147691e-02],\n",
            "       [-3.20778564e-02, -1.44712478e-01, -2.57771984e-02,\n",
            "         1.45197049e-01,  3.41787487e-02, -6.79325163e-02,\n",
            "         2.29536027e-01, -3.77851166e-02, -2.02185512e-02,\n",
            "        -5.00680096e-02],\n",
            "       [-3.47793996e-02, -6.70931935e-02,  9.63169485e-02,\n",
            "         1.94736063e-01, -5.81074916e-02, -1.86026115e-02,\n",
            "         1.56581968e-01,  1.38320163e-01, -3.10080964e-02,\n",
            "         1.49233058e-01],\n",
            "       [-1.67956129e-02, -9.36294645e-02,  1.26889408e-01,\n",
            "         1.73766643e-01,  4.94211242e-02, -2.57420614e-02,\n",
            "         9.49806198e-02,  6.16099983e-02, -6.52612671e-02,\n",
            "         6.16610236e-02],\n",
            "       [ 5.59915509e-03, -5.97400516e-02,  2.53701825e-02,\n",
            "         1.11381739e-01, -1.87627301e-02, -4.22736742e-02,\n",
            "         8.13084021e-02,  3.47517803e-02, -4.58698533e-02,\n",
            "         9.12307296e-03],\n",
            "       [-1.88607834e-02, -1.52817415e-02, -7.35977665e-03,\n",
            "         1.17749080e-01,  4.60687950e-02,  8.39764369e-04,\n",
            "         1.17403209e-01,  1.09225005e-01, -1.11516550e-01,\n",
            "         6.52427366e-03],\n",
            "       [-5.33416308e-02, -1.98717654e-01, -2.64491588e-02,\n",
            "         5.56578450e-02,  1.11744784e-01, -9.21266451e-02,\n",
            "         1.72549427e-01,  8.96077529e-02, -9.04861987e-02,\n",
            "        -5.16050085e-02],\n",
            "       [ 3.97355109e-02, -1.42056078e-01,  4.44999821e-02,\n",
            "         9.09888968e-02, -2.05667634e-02, -8.02283734e-02,\n",
            "         7.48500228e-02, -7.86958411e-02, -8.60449374e-02,\n",
            "        -3.51383560e-03],\n",
            "       [-1.01807468e-01, -1.68246135e-01,  1.94818601e-01,\n",
            "         2.06356749e-01, -2.04665810e-02, -7.04495907e-02,\n",
            "         3.75098027e-02,  1.65367052e-01, -1.65102527e-01,\n",
            "         7.37236440e-02],\n",
            "       [-6.67127734e-03, -1.28243104e-01,  2.13884725e-03,\n",
            "         4.77344096e-02,  2.55223773e-02, -2.57614143e-02,\n",
            "         7.81825706e-02,  1.54027179e-01,  2.18505319e-03,\n",
            "        -1.34474099e-01],\n",
            "       [-5.02949543e-02, -1.03065081e-01,  4.10089977e-02,\n",
            "         8.55302662e-02,  2.18492746e-03, -8.04073811e-02,\n",
            "         1.14789620e-01,  6.16262294e-02,  1.64838340e-02,\n",
            "        -4.58923392e-02],\n",
            "       [-1.74607337e-02, -1.57858089e-01,  1.68222204e-01,\n",
            "         1.40048712e-01, -2.28702873e-02, -7.01648071e-02,\n",
            "         4.67461944e-02,  4.34999494e-03, -3.68992947e-02,\n",
            "         2.13843212e-03],\n",
            "       [-5.71944155e-02, -2.37004340e-01,  2.99491696e-02,\n",
            "         2.40609407e-01, -4.30634022e-02, -8.84077623e-02,\n",
            "         7.80735165e-02, -5.75702861e-02, -1.60597458e-01,\n",
            "        -7.64799416e-02],\n",
            "       [ 5.91936670e-02, -1.18809894e-01, -3.55608836e-02,\n",
            "         2.05854818e-01, -2.87713781e-02, -6.39999576e-04,\n",
            "         5.92383631e-02,  3.93685028e-02, -1.18598767e-01,\n",
            "         2.83995783e-03],\n",
            "       [-6.01560026e-02, -1.18693225e-01,  1.61530137e-01,\n",
            "         1.63016930e-01, -1.29745305e-01, -5.28858081e-02,\n",
            "         5.12623228e-02,  5.46397790e-02, -1.12160318e-01,\n",
            "        -3.67707536e-02]], dtype=float32)>}\n"
          ]
        }
      ],
      "source": [
        "predict_dataset = eval_dataset.map(lambda image, label: image)\n",
        "for batch in predict_dataset.take(1):\n",
        "  print(inference_func(batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osB1LY8WwUJZ"
      },
      "source": [
        "You can also load and do inference in a distributed manner:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iDYvu12zYTmT",
        "outputId": "b2950ed1-ef11-4d1c-8425-dd97406f4800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
          ]
        }
      ],
      "source": [
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(saved_model_path)\n",
        "  inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]\n",
        "\n",
        "  dist_predict_dataset = another_strategy.experimental_distribute_dataset(\n",
        "      predict_dataset)\n",
        "\n",
        "  # Calling the function in a distributed manner\n",
        "  for batch in dist_predict_dataset:\n",
        "    another_strategy.run(inference_func,args=(batch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWGSukoyw3fF"
      },
      "source": [
        "Calling the restored function is just a forward pass on the saved model (predict). What if yout want to continue training the loaded function? Or embed the loaded function into a bigger model? A common practice is to wrap this loaded object to a Keras layer to achieve this. Luckily, [TF Hub](https://www.tensorflow.org/hub) has [hub.KerasLayer](https://github.com/tensorflow/hub/blob/master/tensorflow_hub/keras_layer.py) for this purpose, shown here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "clfk3hQoyKu6",
        "outputId": "b6062042-25eb-4a9c-97ad-678c5143aaba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 29s 28ms/step - loss: 0.2089 - sparse_categorical_accuracy: 0.9387\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0688 - sparse_categorical_accuracy: 0.9801\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "def build_model(loaded):\n",
        "  x = tf.keras.layers.Input(shape=(28, 28, 1), name='input_x')\n",
        "  # Wrap what's loaded to a KerasLayer\n",
        "  keras_layer = hub.KerasLayer(loaded, trainable=True)(x)\n",
        "  model = tf.keras.Model(x, keras_layer)\n",
        "  return model\n",
        "\n",
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(saved_model_path)\n",
        "  model = build_model(loaded)\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "  model.fit(train_dataset, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe1z_OtSJlu2"
      },
      "source": [
        "As you can see, `hub.KerasLayer` wraps the result loaded back from `tf.saved_model.load()` into a Keras layer that can be used to build another model. This is very useful for transfer learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFDOZpK5Wa3W"
      },
      "source": [
        "### Which API should I use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC6GQ9HDLxD6"
      },
      "source": [
        "For saving, if you are working with a keras model, it is almost always recommended to use the Keras's `model.save()` API. If what you are saving is not a Keras model, then the lower level API is your only choice. \n",
        "\n",
        "For loading, which API you use depends on what you want to get from the loading API. If you cannot (or do not want to) get a Keras model, then use `tf.saved_model.load()`. Otherwise, use `tf.keras.models.load_model()`. Note that you can get a Keras model back only if you saved a Keras model. \n",
        "\n",
        "It is possible to mix and match the APIs. You can save a Keras model with `model.save`, and load a non-Keras model with the low-level API, `tf.saved_model.load`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ktwg2GwnXE8v",
        "outputId": "61f739c2-7300-4cdf-8eb9-4465b674521c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "\n",
        "# Saving the model using Keras's save() API\n",
        "model.save(keras_model_path) \n",
        "\n",
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "# Loading the model using lower level API\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(keras_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z7lSj8nZiW5"
      },
      "source": [
        "### Saving/Loading from local device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVAjWcosZodw"
      },
      "source": [
        "When saving and loading from a local io device while running remotely, for example using a cloud TPU, the option `experimental_io_device` must be used to set the io device to localhost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jFcuzsI94bNA",
        "outputId": "0d2507c3-083e-435b-bb3c-cc668dd27d42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "\n",
        "# Saving the model to a path on localhost.\n",
        "saved_model_path = \"/tmp/tf_save\"\n",
        "save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
        "model.save(saved_model_path, options=save_options)\n",
        "\n",
        "# Loading the model from a path on localhost.\n",
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  load_options = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
        "  loaded = tf.keras.models.load_model(saved_model_path, options=load_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJTWOnC9iuA3"
      },
      "source": [
        "### Caveats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzog2ti7YYgy"
      },
      "source": [
        "A special case is when you have a Keras model that does not have well-defined inputs. For example, a Sequential model can be created without any input shapes (`Sequential([Dense(3), ...]`). Subclassed models also do not have well-defined inputs after initialization. In this case, you should stick with the lower level APIs on both saving and loading, otherwise you will get an error. \n",
        "\n",
        "To check if your model has well-defined inputs, just check if `model.inputs` is `None`. If it is not `None`, you are all good. Input shapes are automatically defined when the model is used in `.fit`, `.evaluate`, `.predict`, or when calling the model (`model(inputs)`). \n",
        "\n",
        "Here is an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gurSIbDFjOBc",
        "outputId": "f4b1fc04-321a-4f6f-bc4a-5c01a619039c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.SubclassedModel object at 0x7f596bb20d10>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.SubclassedModel object at 0x7f596bb20d10>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dense.Dense object at 0x7f596bb20e90>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dense.Dense object at 0x7f596bb20e90>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ]
        }
      ],
      "source": [
        "class SubclassedModel(tf.keras.Model):\n",
        "\n",
        "  output_name = 'output_layer'\n",
        "\n",
        "  def __init__(self):\n",
        "    super(SubclassedModel, self).__init__()\n",
        "    self._dense_layer = tf.keras.layers.Dense(\n",
        "        5, dtype=tf.dtypes.float32, name=self.output_name)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self._dense_layer(inputs)\n",
        "\n",
        "my_model = SubclassedModel()\n",
        "# my_model.save(keras_model_path)  # ERROR! \n",
        "tf.saved_model.save(my_model, saved_model_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "save_and_load.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0a90452a8e24df199b907e79ab10298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_106fa58d00414cd09d10ad07d866af12",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ee9250ee6a649fda90b4bad8c89509f",
              "IPY_MODEL_f4b127e5934d40bd9558055c5b637a2a",
              "IPY_MODEL_bc32eb7db52446a59cfe7422feaa8941"
            ]
          }
        },
        "106fa58d00414cd09d10ad07d866af12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ee9250ee6a649fda90b4bad8c89509f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c3f42cfa055482b96f44cd2fd113de3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Dl Completed...: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb61ef0c761047a79ebe85f0e37a7d11"
          }
        },
        "f4b127e5934d40bd9558055c5b637a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1449a037e38490ba9d515fd866f1186",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd6bc1115360430f8a9f0fa300479792"
          }
        },
        "bc32eb7db52446a59cfe7422feaa8941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4685c81ab44640ba940d24d050fbe4f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00,  8.64 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f59d89265d8e4569af91e3fba5539312"
          }
        },
        "0c3f42cfa055482b96f44cd2fd113de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb61ef0c761047a79ebe85f0e37a7d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1449a037e38490ba9d515fd866f1186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd6bc1115360430f8a9f0fa300479792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4685c81ab44640ba940d24d050fbe4f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f59d89265d8e4569af91e3fba5539312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}